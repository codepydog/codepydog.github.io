<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> RAPTOR: Recursive Abstractive Processing for Tree-Organized Retrieval | Yu-Cheng Chang </title> <meta name="author" content="Yu-Cheng Chang"> <meta name="description" content="Stanford's RAPTOR method builds hierarchical text structures through recursive clustering and summarization to solve semantic information loss in traditional RAG text chunking. The approach uses soft clustering, UMAP dimensionality reduction, and Bayesian Information Criterion to optimize retrieval effectiveness while preserving complete semantics."> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://codepydog.github.io/blog/2024/raptor-en/"> <script src="/assets/js/theme.js?a81d82887dd692e91686b43de4542f18"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Yu-Cheng</span> Chang </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">teaching </a> </li> <li class="nav-item "> <a class="nav-link" href="/people/">people </a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">submenus </a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item " href="/books/">bookshelf</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/blog/">blog</a> </div> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">RAPTOR: Recursive Abstractive Processing for Tree-Organized Retrieval</h1> <p class="post-meta"> Created on September 18, 2024 </p> <p class="post-tags"> <a href="/blog/2024"> <i class="fa-solid fa-calendar fa-sm"></i> 2024 </a> ¬† ¬∑ ¬† <a href="/blog/tag/rag"> <i class="fa-solid fa-hashtag fa-sm"></i> rag</a> ¬† <a href="/blog/tag/retrieval"> <i class="fa-solid fa-hashtag fa-sm"></i> retrieval</a> ¬† <a href="/blog/tag/clustering"> <i class="fa-solid fa-hashtag fa-sm"></i> clustering</a> ¬† ¬∑ ¬† <a href="/blog/category/paper"> <i class="fa-solid fa-tag fa-sm"></i> paper</a> ¬† <a href="/blog/category/english"> <i class="fa-solid fa-tag fa-sm"></i> english</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <div class="language-switcher" style="text-align: right; margin-bottom: 20px; padding: 8px 0; border-bottom: 1px solid #333;"> <span style="font-size: 14px; color: #888; margin-right: 8px;">üåê Language:</span> <a href="/blog/2024/raptor-chs/" style="color: #007bff; text-decoration: none; font-weight: 500; transition: opacity 0.2s;" onmouseover="this.style.opacity='0.7'" onmouseout="this.style.opacity='1'">‰∏≠Êñá</a> <span style="color: #666; margin: 0 6px;">|</span> <strong style="color: #007bff; font-weight: 600;">English</strong> </div> <blockquote> <p><strong>Source:</strong> <a href="https://arxiv.org/abs/2401.18059" rel="external nofollow noopener" target="_blank">Paper</a> / <a href="https://github.com/parthsarthi03/raptor" rel="external nofollow noopener" target="_blank">Official GitHub</a></p> </blockquote> <p>This is a paper from Stanford, officially titled <strong><a href="https://arxiv.org/abs/2401.18059" rel="external nofollow noopener" target="_blank">RAPTOR: Recursive Abstractive Processing for Tree-Organized Retrieval</a></strong>. When it first came out earlier this year, I saw many people sharing it on Twitter, and it was also accepted by ICLR, making it quite valuable to read.</p> <p>I assume readers already have basic RAG knowledge, so I won‚Äôt elaborate on that here and will dive directly into the core content of the paper.</p> <h2 id="concept">Concept</h2> <h3 id="the-problem-this-paper-aims-to-solve-deficiencies-of-simple-rag">The Problem This Paper Aims to Solve: Deficiencies of Simple RAG</h3> <blockquote> <p><em>Despite a diversity in methods, the retrieving components of models predominantly rely on standard approaches, i.e., chunking corpora and encoding with BERT-based retrievers. Although this approach is widely adopted, Nair et al. (2023) highlights a potential shortcoming: contiguous segmentation might not capture the complete semantic depth of the text.</em></p> </blockquote> <p>The general RAG creation process includes: chunking text ‚Üí building embeddings ‚Üí when a query comes in, finding relevant text as context. However, when chunking text, semantic information loss in context is inevitable, leading to inability to find relevant text or incomplete information.</p> <p>Therefore, the problem this paper aims to solve is: <strong>How to preserve semantic-level information as much as possible while chunking text.</strong></p> <h3 id="why-do-we-still-need-rag-as-llms-accept-longer-context">Why Do We Still Need RAG as LLMs Accept Longer Context?</h3> <blockquote> <p><em>Why Retrieval? ‚Ä¶ However, as Liu et al. (2023) and Sun et al. (2021) have noted, models tend to underutilize long-range context and see diminishing performance as context length increases, especially when pertinent information is embedded within a lengthy context.</em></p> </blockquote> <p>One of the current LLM development trends is that the tokens that can be input to LLMs are getting longer. For example: GPT-4o (128k), Claude 3.5 Sonnet (200k).</p> <p>At this point, you might think, if we can simply feed all context to the LLM at once, why bother with RAG? Just stuff everything into the LLM and be done with it!</p> <p>Of course, in practice, if you just want to demo a baseline version, this approach is certainly fine. However, if you have quality requirements for model output, you must know that overly long context has the following drawbacks:</p> <ol> <li><strong>Longer context is harder for models to understand, resulting in poorer output quality.</strong></li> <li><strong>Longer context often comes with irrelevant content, which negatively impacts model understanding.</strong></li> <li><strong>Longer context is expensive and slow.</strong></li> </ol> <p>Based on these three points, RAG is still very suitable for LLM products! (Won‚Äôt be eliminated anytime soon)</p> <h2 id="solution">Solution</h2> <h3 id="core-concept-idea">Core Concept (Idea)</h3> <p>As mentioned earlier, the biggest problem with current simple RAG systems is: when splitting text, key information is easily lost, causing semantic incompleteness between text chunks, leading to imprecise retrieval.</p> <p>So how do we preserve the lost key information?</p> <p>The solution proposed in this paper is very concise: <strong>Through continuous clustering and summarization, create a hierarchical structure to preserve semantically similar information as much as possible.</strong></p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/paper/RAPTOR_Recursive_Abstractive_Processing_for_Tree-Organized_Retrieval/raptor_figure1-480.webp 480w,/assets/img/paper/RAPTOR_Recursive_Abstractive_Processing_for_Tree-Organized_Retrieval/raptor_figure1-800.webp 800w,/assets/img/paper/RAPTOR_Recursive_Abstractive_Processing_for_Tree-Organized_Retrieval/raptor_figure1-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/paper/RAPTOR_Recursive_Abstractive_Processing_for_Tree-Organized_Retrieval/raptor_figure1.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="RAPTOR Tree Architecture" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Figure 1. RAPTOR Tree Architecture Overview. </div> <p>This paper‚Äôs method first clusters the leaf layer (the most original chunked text), then summarizes the text in each cluster separately, thereby generating new layer text (corresponding to 6, 7, 8 in the figure). This process is repeated continuously until reaching the preset layer limit, ultimately constructing a tree structure where each layer contains complete information from related text in the previous layer.</p> <p>Simply put, the overall process is roughly as follows:</p> <ol> <li> <strong>First chunk the original text to get the first layer (leaf layer).</strong> Ex: one article ‚Üí 5 chunks (1,2,3,4,5 in Figure 1)</li> <li> <strong>Cluster the text in that layer.</strong> Ex: 5 chunks ‚Üí 3 clusters (gray areas in layer 2 of Figure 1)</li> <li> <strong>Summarize the text in each cluster to get the next layer‚Äôs text.</strong> Ex: 3 clusters ‚Üí 3 new texts (3,5 in Figure 1 generate a summary to get new layer text 6)</li> <li> <strong>Repeat steps 2~3 until reaching Max layer.</strong> Ex: The maximum layer in Figure 1 appears to be 3 layers</li> </ol> <h3 id="clustering">Clustering</h3> <blockquote> <p><em>Clustering plays a key role in building the RAPTOR tree, organizing text segments into cohesive groups. This step groups related content together, which helps the subsequent retrieval process.</em></p> </blockquote> <p>Clustering is the most important aspect of this RAPTOR paper. Essentially, the entire paper uses recursive clustering to generate a hierarchical text structure, allowing RAG systems to obtain richer context.</p> <p>In implementation, to improve clustering effectiveness, the authors made some special treatments:</p> <h4 id="soft-clustering">Soft Clustering</h4> <blockquote> <p><em>One of the unique aspects of our clustering approach is the use of soft clustering, where nodes can belong to multiple clusters without requiring a fixed number of clusters. This flexibility is essential because individual text segments often contain information relevant to various topics, thereby warranting their inclusion in multiple summaries.</em></p> </blockquote> <p>In reality, a text certainly has more than one type. Therefore, the authors consider using soft clustering algorithms, which is <strong>Gaussian Mixture Model (GMM)</strong>.</p> <p>If you‚Äôre not familiar with GMM, that‚Äôs fine. GMM assumes that a text may come from multiple clusters, just with different probabilities of belonging to each cluster.</p> <h4 id="dimension-reduction--umap">Dimension Reduction ‚Äî UMAP</h4> <blockquote> <p><em>The high dimensionality of vector embeddings presents a challenge for traditional GMMs, as distance metrics may behave poorly when used to measure similarity in high-dimensional spaces (Aggarwal et al., 2001). To mitigate this, we employ Uniform Manifold Approximation and Projection (UMAP), a manifold learning technique for dimensionality reduction (McInnes et al., 2018).</em></p> </blockquote> <p>The authors point out that GMM performs poorly in high-dimensional spaces because distance calculation accuracy decreases in high dimensions, and clustering essentially involves calculating distances. Therefore, the authors plan to reduce the dimensionality of embedded text, specifically using <strong>UMAP</strong>. (For example, text embedding originally at 768 dimensions, reduced to 20 dimensions using UMAP)</p> <p>So in practice, how many dimensions should we reduce to?</p> <p>Although the authors mention that poor clustering in high dimensions comes from related paper results, that paper doesn‚Äôt specify exactly how many dimensions should be used, but all their experiments were done at dimension 20, which can be used as a reference.</p> <h4 id="global--local-clustering">Global &amp; Local Clustering</h4> <blockquote> <p><em>‚Ä¶it first identifies global clusters and then performs local clustering within these global clusters. This two-step clustering process captures a broad spectrum of relationships among the text data, from broad themes to specific details.</em></p> </blockquote> <p>The authors designed a two-stage clustering method, first performing global clustering on one layer, then clustering again within each cluster separately. This not only captures high-level clusters but also takes care of detailed items within each cluster.</p> <p>Simply put, two-stage clustering can capture more relationships between texts. Just understand the purpose of two-stage clustering here; for details, you can check the implementation.</p> <h4 id="bayesian-information-criterion-bic">Bayesian Information Criterion (BIC)</h4> <p>The most common problem in clustering is how many clusters to set?</p> <p>The authors directly use <strong>Bayesian Information Criterion</strong> to calculate information scores to decide how many clusters to create. The calculation formula is:</p> \[BIC = -2 \ln(L) + k \ln(N)\] <p>Where N represents the number of text segments, k represents the number of model parameters, and L is the maximum likelihood function value of the model.</p> <h3 id="retrieval">Retrieval</h3> <p>The previous parts were about how to build the knowledge base; now let‚Äôs talk about how to retrieve.</p> <p>There are two methods, each with advantages:</p> <h4 id="tree-traversal-tree-traversal">Tree Traversal (Tree Traversal)</h4> <p><strong>Tree traversal.</strong> Simply put, given root text, find all its children as relevant text for retrieval.</p> <p><strong>Advantages:</strong> Uniform information granularity, obtained text includes broad and detailed text, rich and diverse information.</p> <p><strong>Disadvantages:</strong> Complex retrieval, more places need adjustment (like how many to take from each layer? How deep to go?)</p> <p>In implementation, assume taking the most relevant text from each layer.</p> <h4 id="collapsed-tree-collapsed-tree">Collapsed Tree (Collapsed Tree)</h4> <p><strong>Collapsed tree.</strong> This is simpler, directly flattening the tree and picking the most relevant text when all text is at the same level.</p> <p><strong>Advantages:</strong> Simple retrieval, suitable for answering specific questions (appropriate granularity)</p> <p><strong>Disadvantages:</strong> Uneven retrieval granularity, need to retrieve from every text, higher computational cost.</p> <h4 id="which-retrieval-method-works-better-in-practice">Which Retrieval Method Works Better in Practice?</h4> <p>The authors believe <strong>collapsed tree performs better on average than tree traversal</strong>. Because collapsed tree considers information relevance of all texts, the obtained information granularity is suitable for answering specific questions. In contrast, tree traversal, regardless of how you set the retrieval number for each layer, the proportion of coarse and fine text obtained remains unchanged.</p> <h2 id="summary">Summary</h2> <ul> <li> <strong>What problem does this paper solve?</strong> Text segmentation ‚Üí semantic incompleteness ‚Üí inaccurate retrieval</li> <li> <strong>Solution:</strong> Recursive clustering ‚Üí generate multi-level text, preserve complete semantics</li> </ul> <hr> <h2 id="references">References</h2> <ul> <li><a href="https://arxiv.org/abs/2307.03172" rel="external nofollow noopener" target="_blank">Lost in the Middle: How Language Models Use Long Contexts</a></li> <li><a href="https://arxiv.org/abs/2409.01666" rel="external nofollow noopener" target="_blank">In Defense of RAG in the Era of Long-Context Language Models</a></li> <li><a href="https://link.springer.com/chapter/10.1007/3-540-44503-X_27" rel="external nofollow noopener" target="_blank">On the Surprising Behavior of Distance Metrics in High Dimensional Space</a></li> <li><a href="https://arxiv.org/abs/2409.04701" rel="external nofollow noopener" target="_blank">Late Chunking: Balancing Precision and Cost in Long Context Retrieval</a></li> </ul> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="https://blog.google/technology/ai/google-gemini-update-flash-ai-assistant-io-2024/" target="_blank" rel="external nofollow noopener">Google Gemini updates: Flash 1.5, Gemma 2 and Project Astra</a> <svg width="1rem" height="1rem" viewbox="0 0 30 30" xmlns="http://www.w3.org/2000/svg"> <path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path> </svg> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="https://medium.com/@al-folio/displaying-external-posts-on-your-al-folio-blog-b60a1d241a0a?source=rss-17feae71c3c4------2" target="_blank" rel="external nofollow noopener">Displaying External Posts on Your al-folio Blog</a> <svg width="1rem" height="1rem" viewbox="0 0 30 30" xmlns="http://www.w3.org/2000/svg"> <path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path> </svg> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/3min-paper-illusion-thinking/">[3min-Paper] The_Illusion_of_Thinking</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/illusion-illusion-thinking-en/">The Illusion of the Illusion of Thinking: When AI Evaluation Methods Become Traps for Capability Assessment</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/illusion-illusion-thinking-chs/">[‰∏≠ÊñáÁâà] The Illusion of the Illusion of Thinking: Áï∂AIË©ï‰º∞ÊñπÊ≥ïÊàêÁÇ∫ËÉΩÂäõÂà§Êñ∑ÁöÑÈô∑Èò±</a> </li> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> ¬© Copyright 2025 Yu-Cheng Chang. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>