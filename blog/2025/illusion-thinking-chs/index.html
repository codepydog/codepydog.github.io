<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> [中文版] The Illusion of Thinking: Understanding the Strengths and Limitations of Reasoning Models via the Lens of Problem Complexity | Yu-Cheng Chang </title> <meta name="author" content="Yu-Cheng Chang"> <meta name="description" content="這篇Apple論文發現了一個驚人事實：推理模型並非越複雜越好！研究顯示當問題超過某個複雜度後，即使給模型更多時間思考，表現反而會下降。這挑戰了我們對AI推理能力的基本認知。"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://codepydog.github.io/blog/2025/illusion-thinking-chs/"> <script src="/assets/js/theme.js?a81d82887dd692e91686b43de4542f18"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Yu-Cheng</span> Chang </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">teaching </a> </li> <li class="nav-item "> <a class="nav-link" href="/people/">people </a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">submenus </a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item " href="/books/">bookshelf</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/blog/">blog</a> </div> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">[中文版] The Illusion of Thinking: Understanding the Strengths and Limitations of Reasoning Models via the Lens of Problem Complexity</h1> <p class="post-meta"> Created on June 07, 2025 </p> <p class="post-tags"> <a href="/blog/2025"> <i class="fa-solid fa-calendar fa-sm"></i> 2025 </a>   ·   <a href="/blog/tag/reasoning"> <i class="fa-solid fa-hashtag fa-sm"></i> reasoning</a>   <a href="/blog/tag/llm"> <i class="fa-solid fa-hashtag fa-sm"></i> llm</a>   <a href="/blog/tag/evaluation"> <i class="fa-solid fa-hashtag fa-sm"></i> evaluation</a>   ·   <a href="/blog/category/paper"> <i class="fa-solid fa-tag fa-sm"></i> paper</a>   <a href="/blog/category/chinese"> <i class="fa-solid fa-tag fa-sm"></i> chinese</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <div class="language-switcher" style="text-align: right; margin-bottom: 20px; padding: 8px 0; border-bottom: 1px solid #333;"> <span style="font-size: 14px; color: #888; margin-right: 8px;">🌐 Language:</span> <strong style="color: #007bff; font-weight: 600;">中文</strong> <span style="color: #666; margin: 0 6px;">|</span> <a href="/blog/2025/illusion-thinking-en/" style="color: #007bff; text-decoration: none; font-weight: 500; transition: opacity 0.2s;" onmouseover="this.style.opacity='0.7'" onmouseout="this.style.opacity='1'">English</a> </div> <blockquote> <p><strong>來源：</strong> <a href="https://arxiv.org/pdf/2506.06941" rel="external nofollow noopener" target="_blank">Paper</a></p> </blockquote> <p>這是一篇來自 Apple 的重要論文，全名為 <strong><a href="https://arxiv.org/pdf/2506.06941" rel="external nofollow noopener" target="_blank">The Illusion of Thinking: Understanding the Strengths and Limitations of Reasoning Models via the Lens of Problem Complexity</a></strong>。這篇論文挑戰了我們對大型推理模型能力的基本假設，提出了一個發人深省的問題：當前的推理模型是否真的在「思考」，還是只是在執行複雜的模式匹配？</p> <h2 id="核心問題推理模型的真實能力是什麼">核心問題：推理模型的真實能力是什麼？</h2> <h3 id="現有評估方法的局限性">現有評估方法的局限性</h3> <p>當前對大型語言模型推理能力的評估主要存在以下問題：</p> <blockquote> <p><em>“Current evaluations primarily focus on established mathematical and coding benchmarks, emphasizing final answer accuracy. However, these approaches fail to provide insights into the reasoning traces’ structure and quality.”</em></p> </blockquote> <p><strong>三大核心問題：</strong></p> <ol> <li> <strong>過度關注最終答案準確性</strong>：現有評估主要看結果是否正確，而忽略了推理過程的品質</li> <li> <strong>缺乏對推理結構的深入分析</strong>：沒有系統性地分析模型的內部推理軌跡</li> <li> <strong>對問題複雜度的理解不足</strong>：缺乏從問題複雜度角度來理解模型性能的框架</li> </ol> <h3 id="大型推理模型的興起與挑戰">大型推理模型的興起與挑戰</h3> <p>論文指出了一個關鍵趨勢：</p> <blockquote> <p><em>“Recent generations of frontier language models have introduced Large Reasoning Models (LRMs) that generate detailed thinking processes before providing answers. While these models demonstrate improved performance on reasoning benchmarks, their fundamental capabilities, scaling properties, and limitations remain insufficiently understood.”</em></p> </blockquote> <p>雖然新一代的推理模型（如 Claude 3.7 Thinking、GPT-o1 等）在benchmark上表現優異，但我們對其真實能力的理解仍然不足。</p> <h2 id="創新解決方案基於複雜度的系統性分析框架">創新解決方案：基於複雜度的系統性分析框架</h2> <h3 id="核心方法論">核心方法論</h3> <p>Apple 研究團隊提出了一個革命性的評估框架：</p> <blockquote> <p><em>“In this work, we systematically investigate these aspects of LRMs by constructing puzzle environments that allow precise manipulation of computational complexity while maintaining consistent logical structures.”</em></p> </blockquote> <p><strong>三個關鍵創新：</strong></p> <ol> <li> <p><strong>可控制的拼圖環境設計</strong></p> <ul> <li>精確控制計算複雜度</li> <li>保持一致的邏輯結構</li> <li>消除外部變數干擾</li> </ul> </li> <li> <p><strong>推理軌跡分析</strong></p> <ul> <li>同時分析最終答案和中間推理過程</li> <li>從初始狀態到目標狀態的完整推理路徑驗證</li> <li>多維度性能評估</li> </ul> </li> <li> <p><strong>三個關鍵性能指標</strong></p> <ul> <li><strong>最終答案準確性</strong></li> <li><strong>推理軌跡品質</strong></li> <li><strong>計算效率</strong></li> </ul> </li> </ol> <h3 id="實驗設計的巧思">實驗設計的巧思</h3> <p>研究團隊設計了一個可控制複雜度的拼圖環境，這種設計的優勢在於：</p> <blockquote> <p><em>“This setup enables the analysis of not only final answers but also the internal reasoning traces, offering insights into LRMs’ computational behavior.”</em></p> </blockquote> <p>通過調整拼圖的大小和步驟數，研究者可以精確控制問題的計算複雜度，同時保持邏輯結構的一致性。</p> <h2 id="震撼發現反直覺的複雜度擴展邊界">震撼發現：反直覺的複雜度擴展邊界</h2> <h3 id="核心發現">核心發現</h3> <p>論文最重要的發現挑戰了AI領域的一個基本假設：</p> <blockquote> <p><em>“Moreover, they exhibit a counterintuitive scaling limit: their reasoning effect increases with problem complexity up to a point, then declines despite having an adequate token budget.”</em></p> </blockquote> <p><strong>關鍵洞察：</strong></p> <ul> <li>推理效果隨問題複雜度增加而提升，但只到某個臨界點</li> <li>超過臨界點後，即使有充足的token預算，性能仍會下降</li> <li>這種現象揭示了當前推理模型的根本限制</li> </ul> <h3 id="實驗結果分析">實驗結果分析</h3> <p>從論文的實驗結果可以看到三個重要模式：</p> <ol> <li> <p><strong>準確性vs複雜度曲線</strong>：</p> <ul> <li>隨著複雜度增加，模型準確性呈現倒U型曲線</li> <li>存在一個最佳複雜度點，超過後性能急劇下降</li> </ul> </li> <li> <p><strong>Token使用模式</strong>：</p> <ul> <li>模型會根據問題複雜度動態調整思考長度</li> <li>但在某個點後，增加思考長度無法提升性能</li> </ul> </li> <li> <p><strong>推理品質差異</strong>：</p> <ul> <li>正確解決的案例中，模型傾向於早期找到答案</li> <li>失敗案例中，模型經常專注於錯誤方向，浪費計算資源</li> </ul> </li> </ol> <h2 id="深層思考思考的本質">深層思考：「思考」的本質</h2> <h3 id="推理效率的悖論">推理效率的悖論</h3> <p>論文發現了一個有趣的現象：</p> <blockquote> <p><em>“Both cases reveal inefficiencies in the reasoning process.”</em></p> </blockquote> <p><strong>兩種低效模式：</strong></p> <ol> <li> <strong>過早收斂</strong>：在簡單問題上可能過度思考</li> <li> <strong>錯誤固化</strong>：在複雜問題上容易陷入錯誤思路並難以自我糾正</li> </ol> <h3 id="對agi發展的啟示">對AGI發展的啟示</h3> <p>論文提出了一個深刻的哲學問題：</p> <blockquote> <p><em>“emergence suggests a potential paradigm shift in how LLM systems approach complex reasoning and problem-solving tasks, with some researchers proposing them as significant steps toward more general artificial intelligence capabilities.”</em></p> </blockquote> <p>但同時也保持了理性的態度：</p> <blockquote> <p><em>“Despite these claims and performance advancements, the fundamental benefits and limitations of LRMs remain insufficiently understood.”</em></p> </blockquote> <h2 id="實用價值與未來方向">實用價值與未來方向</h2> <h3 id="對實際應用的指導意義">對實際應用的指導意義</h3> <p>這項研究為AI應用提供了重要的實用指導：</p> <p><strong>1. 成本優化策略</strong></p> <ul> <li>幫助確定最佳的推理資源配置</li> <li>避免在超過最佳複雜度點的任務上浪費資源</li> </ul> <p><strong>2. 性能預期管理</strong></p> <ul> <li>為不同複雜度的任務設定合理的性能預期</li> <li>理解模型能力的邊界</li> </ul> <p><strong>3. 模型選擇指南</strong></p> <ul> <li>為特定應用選擇合適的推理模型</li> <li>平衡性能與成本</li> </ul> <h3 id="未來研究方向">未來研究方向</h3> <p>這項工作開啟了幾個重要的研究方向：</p> <p><strong>1. 適應性推理</strong></p> <ul> <li>如何讓模型根據問題複雜度動態調整推理策略</li> <li>開發複雜度感知的推理算法</li> </ul> <p><strong>2. 推理效率優化</strong></p> <ul> <li>如何在保持準確性的同時提高推理效率</li> <li>設計更智能的計算資源分配機制</li> </ul> <p><strong>3. 評估方法學創新</strong></p> <ul> <li>發展更全面的推理能力評估框架</li> <li>關注過程而非僅僅關注結果</li> </ul> <h2 id="心得">心得</h2> <h3 id="與人類認知的相似性">與人類認知的相似性</h3> <p>這項研究讓我想到人類在解決複雜問題時的認知模式。人類也會經歷類似的「效率邊界」：</p> <ul> <li> <strong>過度思考的陷阱</strong>：有時候想太多反而會降低問題解決的效果</li> <li> <strong>認知負荷限制</strong>：超過認知容量後，思考品質會下降</li> <li> <strong>直覺vs分析</strong>：簡單問題靠直覺，複雜問題需要系統性分析</li> </ul> <p>這種相似性是否暗示當前的推理模型在某種程度上確實捕捉到了認知過程的某些特徵？</p> <h3 id="對快思慢想理論的呼應">對「快思慢想」理論的呼應</h3> <p>這項研究似乎為Daniel Kahneman的「快思慢想」理論在AI中的應用提供了實證支持：</p> <ul> <li> <strong>系統1（快思）</strong>：適合處理簡單、熟悉的問題</li> <li> <strong>系統2（慢想）</strong>：適合處理複雜、需要深度分析的問題</li> </ul> <p>模型在不同複雜度問題上的表現差異，呼應了人類認知的雙系統理論。</p> <h3 id="對ai安全的思考">對AI安全的思考</h3> <p>這項研究也提醒我們關注AI系統的可靠性：</p> <ul> <li> <strong>能力邊界的重要性</strong>：了解模型的限制對於安全部署至關重要</li> <li> <strong>過度自信的風險</strong>：模型可能在超出能力範圍的問題上表現出不當的自信</li> <li> <strong>可解釋性的必要性</strong>：需要更好地理解模型的推理過程</li> </ul> <h2 id="結論">結論</h2> <p>這篇論文為我們理解大型推理模型提供了全新的視角。通過揭示「推理效果的複雜度邊界」這一反直覺現象，它挑戰了我們對AI能力的基本假設，提醒我們在追求更強大的AI系統時，需要更深入地理解這些系統的工作原理。</p> <p><strong>核心啟示：</strong></p> <ul> <li>更多計算資源並不總是帶來更好的性能</li> <li>推理模型存在根本性的能力邊界</li> <li>我們需要重新思考如何評估和優化推理能力</li> </ul> <p>這項工作不僅為當前的AI研究提供了重要洞察，也為未來構建更可靠、更高效的推理系統指明了方向。正如論文標題所暗示的，我們需要透過「思考的幻象」，看到推理模型的真實本質。</p> <hr> <h2 id="參考文獻">參考文獻</h2> <ul> <li><a href="https://arxiv.org/pdf/2506.06941" rel="external nofollow noopener" target="_blank">The Illusion of Thinking: Understanding the Strengths and Limitations of Reasoning Models via the Lens of Problem Complexity</a></li> <li><a href="https://en.wikipedia.org/wiki/Thinking,_Fast_and_Slow" rel="external nofollow noopener" target="_blank">Thinking, Fast and Slow - Daniel Kahneman</a></li> </ul> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="https://blog.google/technology/ai/google-gemini-update-flash-ai-assistant-io-2024/" target="_blank" rel="external nofollow noopener">Google Gemini updates: Flash 1.5, Gemma 2 and Project Astra</a> <svg width="1rem" height="1rem" viewbox="0 0 30 30" xmlns="http://www.w3.org/2000/svg"> <path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path> </svg> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="https://medium.com/@al-folio/displaying-external-posts-on-your-al-folio-blog-b60a1d241a0a?source=rss-17feae71c3c4------2" target="_blank" rel="external nofollow noopener">Displaying External Posts on Your al-folio Blog</a> <svg width="1rem" height="1rem" viewbox="0 0 30 30" xmlns="http://www.w3.org/2000/svg"> <path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path> </svg> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/3min-paper-illusion-thinking/">[3min-Paper] The_Illusion_of_Thinking</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/illusion-illusion-thinking-en/">The Illusion of the Illusion of Thinking: When AI Evaluation Methods Become Traps for Capability Assessment</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/illusion-illusion-thinking-chs/">[中文版] The Illusion of the Illusion of Thinking: 當AI評估方法成為能力判斷的陷阱</a> </li> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Yu-Cheng Chang. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>